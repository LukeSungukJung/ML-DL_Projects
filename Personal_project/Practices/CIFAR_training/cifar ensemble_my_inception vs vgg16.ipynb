{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import cifar10\nfrom keras.models import *\nfrom keras.layers import *\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import *\nfrom keras.preprocessing import image\nfrom keras import regularizers,optimizers\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\n \ndef lr_schedule(epoch):\n    lrate = 0.001\n    if epoch < 2:\n        lrate = 0.005\n    if epoch > 20:\n        lrate = 0.0005\n    if epoch > 30:\n        lrate = 0.0001\n    if epoch > 42:\n        lrate = 0.00007\n    if epoch > 60:\n        lrate = 0.00003\n    if epoch > 100:\n        lrate = 0.00001\n    if epoch > 120:\n        lrate = 0.0001\n    return lrate\n ","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train =np.asarray([one/255 for one in x_train])\ny_train = to_categorical(y_train)\n\nx_test = np.asarray([one/255 for one in x_test])\ny_test_pure = y_test\ny_test =to_categorical(y_test)\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    )\ndatagen.fit(x_train)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv2d_bn(x,\n              filters,\n              kernel_size,\n              strides=1,\n              padding='same',\n              activation='relu',\n              use_bias=True,\n              name=None):\n    \n    x = layers.Conv2D(filters,\n                      kernel_size,\n                      strides=strides,\n                      padding=padding,\n                      use_bias=use_bias,\n                      name=name)(x)\n    if activation is not None:\n        ac_name = None if name is None else name + '_ac'\n        x = layers.Activation(activation, name=ac_name)(x)\n    return x","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n\nmy inception\nimg_input = Input(shape=(32,32,3))\nlayer1 =  Conv2D(16,(3,3),padding='same',use_bias=True)(img_input)\nlayer1 = Conv2D(32, (3, 3),padding='same',use_bias=True)(layer1)\nlayer1 = MaxPooling2D((2, 2))(layer1)\n\n\nbranch_1 = Conv2D(8,(1,1),padding='same',use_bias=True)(layer1)\n\nbranch_2 = Conv2D(16,(2,2),padding='same',use_bias=True)(layer1)\nbranch_2 = Conv2D(8,(2,2),padding='same',use_bias=True)(layer1)\nbranch_2 = MaxPool2D(1,1)(branch_2)\n\nbranch_3 = Conv2D(16,(1,1),padding='same',use_bias=True)(layer1)\nbranch_3 = Conv2D(32,(3,3),padding='same',use_bias=True)(branch_3)\nbranch_3 = Conv2D(8,(2,2),padding='same',use_bias=True)(branch_3)\n\nbranch_pool =AveragePooling2D((3, 3),strides=(1, 1),padding='same')(layer1)\nbranch_pool = Conv2D(8,(1,1),padding='same',use_bias=True)(branch_pool)\n\nconcat_conv = concatenate([branch_1,branch_2,branch_3,branch_pool],axis=1)\n\nbranch_1 = Conv2D(8,(1,1),padding='same',use_bias=True)(layer1)\n\nbranch_2 = Conv2D(32,(2,2),padding='same',use_bias=True)(layer1)\nbranch_2 = Conv2D(16,(2,2),padding='same',use_bias=True)(layer1)\nbranch_2 = MaxPool2D(1,1)(branch_2)\n\nbranch_3 = Conv2D(64,(1,1),padding='same',use_bias=True)(layer1)\nbranch_3 = Conv2D(96,(3,3),padding='same',use_bias=True)(branch_3)\nbranch_3 = Conv2D(16,(2,2),padding='same',use_bias=True)(branch_3)\n\nbranch_pool =AveragePooling2D((3, 3),strides=(1, 1),padding='same')(layer1)\nbranch_pool = Conv2D(16,(1,1),padding='same',use_bias=True)(branch_pool)\n\nconcat_conv = concatenate([branch_1,branch_2,branch_3,branch_pool],axis=3)\nflt = GlobalAveragePooling2D()(concat_conv)\nDen = Dense(256,activation='relu')(flt)\nDen = Dropout(0.5)(Den)\nres = Dense(100,activation='softmax')(Den)\n\nmodel = Model(img_input,res)\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\nmodel.summary()\n\"\"\"","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"\"\\n\\nmy inception\\nimg_input = Input(shape=(32,32,3))\\nlayer1 =  Conv2D(16,(3,3),padding='same',use_bias=True)(img_input)\\nlayer1 = Conv2D(32, (3, 3),padding='same',use_bias=True)(layer1)\\nlayer1 = MaxPooling2D((2, 2))(layer1)\\n\\n\\nbranch_1 = Conv2D(8,(1,1),padding='same',use_bias=True)(layer1)\\n\\nbranch_2 = Conv2D(16,(2,2),padding='same',use_bias=True)(layer1)\\nbranch_2 = Conv2D(8,(2,2),padding='same',use_bias=True)(layer1)\\nbranch_2 = MaxPool2D(1,1)(branch_2)\\n\\nbranch_3 = Conv2D(16,(1,1),padding='same',use_bias=True)(layer1)\\nbranch_3 = Conv2D(32,(3,3),padding='same',use_bias=True)(branch_3)\\nbranch_3 = Conv2D(8,(2,2),padding='same',use_bias=True)(branch_3)\\n\\nbranch_pool =AveragePooling2D((3, 3),strides=(1, 1),padding='same')(layer1)\\nbranch_pool = Conv2D(8,(1,1),padding='same',use_bias=True)(branch_pool)\\n\\nconcat_conv = concatenate([branch_1,branch_2,branch_3,branch_pool],axis=1)\\n\\nbranch_1 = Conv2D(8,(1,1),padding='same',use_bias=True)(layer1)\\n\\nbranch_2 = Conv2D(32,(2,2),padding='same',use_bias=True)(layer1)\\nbranch_2 = Conv2D(16,(2,2),padding='same',use_bias=True)(layer1)\\nbranch_2 = MaxPool2D(1,1)(branch_2)\\n\\nbranch_3 = Conv2D(64,(1,1),padding='same',use_bias=True)(layer1)\\nbranch_3 = Conv2D(96,(3,3),padding='same',use_bias=True)(branch_3)\\nbranch_3 = Conv2D(16,(2,2),padding='same',use_bias=True)(branch_3)\\n\\nbranch_pool =AveragePooling2D((3, 3),strides=(1, 1),padding='same')(layer1)\\nbranch_pool = Conv2D(16,(1,1),padding='same',use_bias=True)(branch_pool)\\n\\nconcat_conv = concatenate([branch_1,branch_2,branch_3,branch_pool],axis=3)\\nflt = GlobalAveragePooling2D()(concat_conv)\\nDen = Dense(256,activation='relu')(flt)\\nDen = Dropout(0.5)(Den)\\nres = Dense(100,activation='softmax')(Den)\\n\\nmodel = Model(img_input,res)\\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\\nmodel.summary()\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_conv_model_list():\n    weight_decay = 1e-4\n    model = Sequential()\n    model.add(Conv2D(32,(2,2),use_bias=True,activation='elu',padding='same',input_shape=(32,32,3),kernel_regularizer=regularizers.l2(weight_decay)))\n    model.add(MaxPool2D(2,2))\n    model.add(BatchNormalization())\n    model.add(ZeroPadding2D(padding=(1, 1), data_format=None))\n    model.add(Conv2D(64,(4,4),use_bias=True,padding='same',activation='elu',kernel_regularizer=regularizers.l2(weight_decay)))\n    model.add(MaxPool2D(2,2))\n    model.add(BatchNormalization())\n    model.add(ZeroPadding2D(padding=(1, 1), data_format=None))\n    model.add(Conv2D(128,(2,2),use_bias=True,padding='same',activation='elu',kernel_regularizer=regularizers.l2(weight_decay)))\n    model.add(MaxPool2D(2,2))\n    model.add(Flatten())\n    model.add(Dense(64,activation='elu'))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dense(32,activation='elu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))\n    opt_rms = optimizers.rmsprop(lr=0.001,decay=1e-6)\n    model.compile(optimizer=opt_rms,loss='categorical_crossentropy',metrics=['acc'])\n    model.summary()\n    return model","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_model_list = []\nensemble_size=5\nensemble_call_back =[LearningRateScheduler(lr_schedule)]\nfor i in range(ensemble_size):\n    this_model = make_conv_model_list()\n    print('i_th model training')\n    this_model.fit_generator(datagen.flow(x_train, y_train, batch_size=125),\\\n                    steps_per_epoch=x_train.shape[0] // 125,epochs=200,\\\n                    verbose=1,validation_data=(x_test,y_test),callbacks=ensemble_call_back)\n    \n    ensemble_model_list.append(this_model)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_28 (Conv2D)           (None, 32, 32, 32)        416       \n_________________________________________________________________\nmax_pooling2d_28 (MaxPooling (None, 16, 16, 32)        0         \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 16, 16, 32)        128       \n_________________________________________________________________\nzero_padding2d_19 (ZeroPaddi (None, 18, 18, 32)        0         \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 18, 18, 64)        32832     \n_________________________________________________________________\nmax_pooling2d_29 (MaxPooling (None, 9, 9, 64)          0         \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 9, 9, 64)          256       \n_________________________________________________________________\nzero_padding2d_20 (ZeroPaddi (None, 11, 11, 64)        0         \n_________________________________________________________________\nconv2d_30 (Conv2D)           (None, 11, 11, 128)       32896     \n_________________________________________________________________\nmax_pooling2d_30 (MaxPooling (None, 5, 5, 128)         0         \n_________________________________________________________________\nflatten_10 (Flatten)         (None, 3200)              0         \n_________________________________________________________________\ndense_22 (Dense)             (None, 64)                204864    \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 64)                0         \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 64)                256       \n_________________________________________________________________\ndense_23 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 32)                0         \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                330       \n=================================================================\nTotal params: 274,058\nTrainable params: 273,738\nNon-trainable params: 320\n_________________________________________________________________\ni_th model training\nEpoch 1/125\n400/400 [==============================] - 25s 62ms/step - loss: 1.8284 - acc: 0.3408 - val_loss: 1.9974 - val_acc: 0.3190\nEpoch 2/125\n400/400 [==============================] - 21s 54ms/step - loss: 1.5257 - acc: 0.4660 - val_loss: 1.3002 - val_acc: 0.5592\nEpoch 3/125\n400/400 [==============================] - 21s 54ms/step - loss: 1.3348 - acc: 0.5465 - val_loss: 1.1853 - val_acc: 0.5931\nEpoch 4/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.2707 - acc: 0.5756 - val_loss: 1.0903 - val_acc: 0.6340\nEpoch 5/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.2316 - acc: 0.5930 - val_loss: 1.0765 - val_acc: 0.6442\nEpoch 6/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.2039 - acc: 0.6042 - val_loss: 1.0895 - val_acc: 0.6350\nEpoch 7/125\n400/400 [==============================] - 21s 53ms/step - loss: 1.1761 - acc: 0.6172 - val_loss: 1.1000 - val_acc: 0.6514\nEpoch 8/125\n400/400 [==============================] - 21s 54ms/step - loss: 1.1564 - acc: 0.6225 - val_loss: 0.9335 - val_acc: 0.6928\nEpoch 9/125\n400/400 [==============================] - 21s 53ms/step - loss: 1.1395 - acc: 0.6331 - val_loss: 0.9752 - val_acc: 0.6848\nEpoch 10/125\n400/400 [==============================] - 22s 55ms/step - loss: 1.1140 - acc: 0.6416 - val_loss: 0.9621 - val_acc: 0.6810\nEpoch 11/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.0983 - acc: 0.6460 - val_loss: 0.9148 - val_acc: 0.7040\nEpoch 12/125\n400/400 [==============================] - 21s 54ms/step - loss: 1.0842 - acc: 0.6514 - val_loss: 0.9970 - val_acc: 0.6739\nEpoch 13/125\n400/400 [==============================] - 21s 53ms/step - loss: 1.0726 - acc: 0.6579 - val_loss: 1.0522 - val_acc: 0.6698\nEpoch 14/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.0652 - acc: 0.6623 - val_loss: 0.9507 - val_acc: 0.6913\nEpoch 15/125\n400/400 [==============================] - 22s 55ms/step - loss: 1.0433 - acc: 0.6680 - val_loss: 1.0041 - val_acc: 0.6815\nEpoch 16/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.0300 - acc: 0.6735 - val_loss: 1.1545 - val_acc: 0.6428\nEpoch 17/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.0294 - acc: 0.6743 - val_loss: 0.9958 - val_acc: 0.6828\nEpoch 18/125\n400/400 [==============================] - 21s 53ms/step - loss: 1.0233 - acc: 0.6794 - val_loss: 0.9014 - val_acc: 0.7097\nEpoch 19/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.0094 - acc: 0.6854 - val_loss: 0.8859 - val_acc: 0.7258\nEpoch 20/125\n400/400 [==============================] - 22s 54ms/step - loss: 1.0005 - acc: 0.6899 - val_loss: 0.8654 - val_acc: 0.7289\nEpoch 21/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.9904 - acc: 0.6904 - val_loss: 0.8826 - val_acc: 0.7195\nEpoch 22/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.9553 - acc: 0.7046 - val_loss: 0.8130 - val_acc: 0.7436\nEpoch 23/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.9399 - acc: 0.7105 - val_loss: 0.7926 - val_acc: 0.7480\nEpoch 24/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.9304 - acc: 0.7148 - val_loss: 0.9364 - val_acc: 0.7084\nEpoch 25/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.9288 - acc: 0.7140 - val_loss: 0.8520 - val_acc: 0.7312\nEpoch 26/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.9226 - acc: 0.7174 - val_loss: 0.8405 - val_acc: 0.7327\nEpoch 27/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.9182 - acc: 0.7180 - val_loss: 0.7671 - val_acc: 0.7556\nEpoch 28/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.9137 - acc: 0.7207 - val_loss: 0.9412 - val_acc: 0.7078\nEpoch 29/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.9080 - acc: 0.7226 - val_loss: 0.9143 - val_acc: 0.7192\nEpoch 30/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.9077 - acc: 0.7226 - val_loss: 0.7822 - val_acc: 0.7549\nEpoch 31/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8996 - acc: 0.7246 - val_loss: 0.8279 - val_acc: 0.7352\nEpoch 32/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8743 - acc: 0.7328 - val_loss: 0.7489 - val_acc: 0.7670\nEpoch 33/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8632 - acc: 0.7382 - val_loss: 0.7542 - val_acc: 0.7635\nEpoch 34/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8626 - acc: 0.7376 - val_loss: 0.7537 - val_acc: 0.7625\nEpoch 35/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8594 - acc: 0.7393 - val_loss: 0.7511 - val_acc: 0.7645\nEpoch 36/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8569 - acc: 0.7397 - val_loss: 0.7167 - val_acc: 0.7738\nEpoch 37/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8536 - acc: 0.7410 - val_loss: 0.7433 - val_acc: 0.7685\nEpoch 38/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8502 - acc: 0.7433 - val_loss: 0.7205 - val_acc: 0.7759\nEpoch 39/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8441 - acc: 0.7446 - val_loss: 0.7361 - val_acc: 0.7725\nEpoch 40/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8442 - acc: 0.7447 - val_loss: 0.7497 - val_acc: 0.7647\nEpoch 41/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8390 - acc: 0.7455 - val_loss: 0.7316 - val_acc: 0.7707\nEpoch 42/125\n","name":"stdout"},{"output_type":"stream","text":"400/400 [==============================] - 22s 55ms/step - loss: 0.8461 - acc: 0.7455 - val_loss: 0.7248 - val_acc: 0.7732\nEpoch 43/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8422 - acc: 0.7464 - val_loss: 0.7223 - val_acc: 0.7750\nEpoch 44/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8410 - acc: 0.7445 - val_loss: 0.7549 - val_acc: 0.7640\nEpoch 45/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8358 - acc: 0.7472 - val_loss: 0.7278 - val_acc: 0.7718\nEpoch 46/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8358 - acc: 0.7488 - val_loss: 0.7185 - val_acc: 0.7753\nEpoch 47/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8330 - acc: 0.7486 - val_loss: 0.7221 - val_acc: 0.7725\nEpoch 48/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8302 - acc: 0.7485 - val_loss: 0.7392 - val_acc: 0.7697\nEpoch 49/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8389 - acc: 0.7456 - val_loss: 0.7199 - val_acc: 0.7750\nEpoch 50/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8335 - acc: 0.7469 - val_loss: 0.7324 - val_acc: 0.7724\nEpoch 51/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8276 - acc: 0.7478 - val_loss: 0.7178 - val_acc: 0.7766\nEpoch 52/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8291 - acc: 0.7511 - val_loss: 0.7436 - val_acc: 0.7696\nEpoch 53/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8301 - acc: 0.7472 - val_loss: 0.7104 - val_acc: 0.7765\nEpoch 54/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8269 - acc: 0.7499 - val_loss: 0.7173 - val_acc: 0.7758\nEpoch 55/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8299 - acc: 0.7484 - val_loss: 0.7390 - val_acc: 0.7702\nEpoch 56/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8254 - acc: 0.7521 - val_loss: 0.7309 - val_acc: 0.7729\nEpoch 57/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8254 - acc: 0.7514 - val_loss: 0.7235 - val_acc: 0.7740\nEpoch 58/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8218 - acc: 0.7510 - val_loss: 0.7454 - val_acc: 0.7669\nEpoch 59/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8198 - acc: 0.7529 - val_loss: 0.7361 - val_acc: 0.7711\nEpoch 60/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8258 - acc: 0.7505 - val_loss: 0.7140 - val_acc: 0.7775\nEpoch 61/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8242 - acc: 0.7513 - val_loss: 0.7246 - val_acc: 0.7749\nEpoch 62/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8140 - acc: 0.7540 - val_loss: 0.7128 - val_acc: 0.7783\nEpoch 63/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8167 - acc: 0.7513 - val_loss: 0.7149 - val_acc: 0.7756\nEpoch 64/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8157 - acc: 0.7547 - val_loss: 0.7107 - val_acc: 0.7782\nEpoch 65/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8170 - acc: 0.7538 - val_loss: 0.7119 - val_acc: 0.7764\nEpoch 66/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8110 - acc: 0.7563 - val_loss: 0.7245 - val_acc: 0.7754\nEpoch 67/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8157 - acc: 0.7544 - val_loss: 0.7002 - val_acc: 0.7825\nEpoch 68/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8118 - acc: 0.7537 - val_loss: 0.7142 - val_acc: 0.7778\nEpoch 69/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8119 - acc: 0.7535 - val_loss: 0.7275 - val_acc: 0.7741\nEpoch 70/125\n400/400 [==============================] - 23s 57ms/step - loss: 0.8124 - acc: 0.7546 - val_loss: 0.7132 - val_acc: 0.7774\nEpoch 71/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8132 - acc: 0.7540 - val_loss: 0.7136 - val_acc: 0.7783\nEpoch 72/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8141 - acc: 0.7539 - val_loss: 0.7179 - val_acc: 0.7779\nEpoch 73/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8127 - acc: 0.7565 - val_loss: 0.7254 - val_acc: 0.7758\nEpoch 74/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8146 - acc: 0.7542 - val_loss: 0.7196 - val_acc: 0.7769\nEpoch 75/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8125 - acc: 0.7545 - val_loss: 0.6907 - val_acc: 0.7844\nEpoch 76/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8139 - acc: 0.7540 - val_loss: 0.7062 - val_acc: 0.7803\nEpoch 77/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8151 - acc: 0.7527 - val_loss: 0.7159 - val_acc: 0.7786\nEpoch 78/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8081 - acc: 0.7559 - val_loss: 0.7057 - val_acc: 0.7814\nEpoch 79/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8087 - acc: 0.7544 - val_loss: 0.7127 - val_acc: 0.7793\nEpoch 80/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8042 - acc: 0.7564 - val_loss: 0.7188 - val_acc: 0.7771\nEpoch 81/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8050 - acc: 0.7558 - val_loss: 0.7272 - val_acc: 0.7760\nEpoch 82/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8015 - acc: 0.7562 - val_loss: 0.7274 - val_acc: 0.7759\nEpoch 83/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8083 - acc: 0.7568 - val_loss: 0.7061 - val_acc: 0.7806\nEpoch 84/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8104 - acc: 0.7549 - val_loss: 0.7090 - val_acc: 0.7810\nEpoch 85/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8063 - acc: 0.7566 - val_loss: 0.7280 - val_acc: 0.7761\nEpoch 86/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8058 - acc: 0.7564 - val_loss: 0.7150 - val_acc: 0.7780\nEpoch 87/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8079 - acc: 0.7559 - val_loss: 0.7070 - val_acc: 0.7810\nEpoch 88/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8074 - acc: 0.7556 - val_loss: 0.7110 - val_acc: 0.7795\nEpoch 89/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8090 - acc: 0.7559 - val_loss: 0.7295 - val_acc: 0.7752\nEpoch 90/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8078 - acc: 0.7559 - val_loss: 0.7203 - val_acc: 0.7761\nEpoch 91/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8076 - acc: 0.7552 - val_loss: 0.7109 - val_acc: 0.7785\nEpoch 92/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8068 - acc: 0.7564 - val_loss: 0.7042 - val_acc: 0.7802\nEpoch 93/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8084 - acc: 0.7556 - val_loss: 0.7092 - val_acc: 0.7797\nEpoch 94/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8045 - acc: 0.7573 - val_loss: 0.7001 - val_acc: 0.7838\nEpoch 95/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8022 - acc: 0.7558 - val_loss: 0.7076 - val_acc: 0.7811\nEpoch 96/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8060 - acc: 0.7556 - val_loss: 0.7087 - val_acc: 0.7809\nEpoch 97/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8110 - acc: 0.7530 - val_loss: 0.6959 - val_acc: 0.7841\nEpoch 98/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8077 - acc: 0.7560 - val_loss: 0.7278 - val_acc: 0.7773\nEpoch 99/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.8015 - acc: 0.7585 - val_loss: 0.7190 - val_acc: 0.7774\nEpoch 100/125\n400/400 [==============================] - 23s 57ms/step - loss: 0.8026 - acc: 0.7560 - val_loss: 0.7092 - val_acc: 0.7807\nEpoch 101/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.7979 - acc: 0.7591 - val_loss: 0.6955 - val_acc: 0.7834\nEpoch 102/125\n","name":"stdout"},{"output_type":"stream","text":"400/400 [==============================] - 22s 54ms/step - loss: 0.7952 - acc: 0.7588 - val_loss: 0.7059 - val_acc: 0.7799\nEpoch 103/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8002 - acc: 0.7596 - val_loss: 0.7016 - val_acc: 0.7816\nEpoch 104/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8026 - acc: 0.7574 - val_loss: 0.6972 - val_acc: 0.7832\nEpoch 105/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.8019 - acc: 0.7589 - val_loss: 0.7048 - val_acc: 0.7804\nEpoch 106/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.7990 - acc: 0.7596 - val_loss: 0.6977 - val_acc: 0.7835\nEpoch 107/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.7945 - acc: 0.7618 - val_loss: 0.7055 - val_acc: 0.7801\nEpoch 108/125\n400/400 [==============================] - 21s 53ms/step - loss: 0.8002 - acc: 0.7588 - val_loss: 0.7054 - val_acc: 0.7816\nEpoch 109/125\n400/400 [==============================] - 21s 54ms/step - loss: 0.7954 - acc: 0.7598 - val_loss: 0.7042 - val_acc: 0.7807\nEpoch 110/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8015 - acc: 0.7593 - val_loss: 0.7016 - val_acc: 0.7820\nEpoch 111/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.7964 - acc: 0.7596 - val_loss: 0.7023 - val_acc: 0.7809\nEpoch 112/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.7975 - acc: 0.7603 - val_loss: 0.7082 - val_acc: 0.7797\nEpoch 113/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.7998 - acc: 0.7580 - val_loss: 0.7015 - val_acc: 0.7814\nEpoch 114/125\n400/400 [==============================] - 22s 56ms/step - loss: 0.7963 - acc: 0.7606 - val_loss: 0.7047 - val_acc: 0.7818\nEpoch 115/125\n400/400 [==============================] - 22s 54ms/step - loss: 0.8005 - acc: 0.7594 - val_loss: 0.7053 - val_acc: 0.7810\nEpoch 116/125\n400/400 [==============================] - 22s 55ms/step - loss: 0.7992 - acc: 0.7610 - val_loss: 0.7093 - val_acc: 0.7793\nEpoch 117/125\n 24/400 [>.............................] - ETA: 17s - loss: 0.8372 - acc: 0.7467","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_predicted = np.zeros(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for one in ensemble_model_list:\n    all_predicted =all_predicted+one.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_res = []\nfor one in all_predicted:\n    final_res.append(np.argmax(one))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_res = np.asarray(final_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"entire = y_test_pure.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ele = 0\nfor one in range(entire):\n    if(y_test_pure[one]==final_res[one]):\n        ele=ele+1\n    \nres_acc = ele/entire","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}